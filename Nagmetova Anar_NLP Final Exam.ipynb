{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BsP8X727kQMe"
   },
   "source": [
    "<h3 style=\"text-align: center;\"><b>NLP Final Exam</b></h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-2rBvEkkQMj"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHc7UePMkQMp"
   },
   "source": [
    "# Дисклеймер про CrossEntropyLoss и NLLLoss\n",
    "\n",
    "Обычно в PyTorch не нужно делать Softmax как последний слой модели. \n",
    "\n",
    "* Если Вы используете NLLLoss, то ему на вход надо давать лог вероятности, то есть выход слоя LogSoftmax. (Просто результат софтмакса, к которому применен логарифм)\n",
    "* Если Вы используете CrossEntropyLoss, то применение LogSoftmax уже включено внутрь лосса, поэтому ему на вход надо подавать просто выход обычного линейного слоя без активации. По сути CrossEntropyLoss = LogSoftmax + NLLLoss\n",
    "\n",
    "Зачем такие сложности, чтобы посчитать обычную кросс энтропию? Дело в том, что нам в любом случае придется взять логарифм от результатов софтмакса, а если делать это одной функцией, то можно сделать более устойчивую реализацию, которая даст меньшую вычислительную погрешность. \n",
    "\n",
    "Таким образом, если у вас в конце сети, решающей задачу классификации, стоит просто линейный слой без активации, то вам нужно использовать CrossEntropy. В notebook используется лосс CrossEntropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8rM9IY0YkQMq"
   },
   "source": [
    "# Задание 1. Создайте генератор батчей. \n",
    "\n",
    "В этот раз мы хотим сделать генератор, который будет максимально похож на то, что используется в реальном обучении. \n",
    "\n",
    "С помощью numpy вам нужно перемешать исходную выборку и выбирать из нее батчи размером batch_size, если размер выборки не делился на размер батча, то последний батч должен иметь размер меньше batch_size и состоять просто из всех оставшихся объектов. Возвращать нужно в формате (X_batch, y_batch). Необходимо написать именно генератор, то есть вместо return использовать yield. \n",
    "\n",
    "Хорошая статья про генераторы: https://habr.com/ru/post/132554/\n",
    "\n",
    "\n",
    "**Ответ на задание - код**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ttf6PZuVkQMr"
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size):\n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(X))\n",
    "    \n",
    "    for i in range(len(X)//batch_size):\n",
    "        if len(X)%batch_size == 0:\n",
    "            if len(y) == batch_size:\n",
    "                yield X[i*batch_size: (i+1)*batch_size], y[i*batch_size: (i+1)*batch_size]\n",
    "        else:\n",
    "            yield X[len(X):], y[len(X):]\n",
    "    # YOUR CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RvSIsl-c5lW"
   },
   "source": [
    "Попробуем потестировать наш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U_snYtUUcpDy"
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-18ab24a341ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Проверим shape первого батча\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from inspect import isgeneratorfunction\n",
    "assert isgeneratorfunction(batch_generator), \"batch_generator должен быть генератором! В условии есть ссылка на доки\"\n",
    "\n",
    "X = np.array([\n",
    "              [1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]\n",
    "])\n",
    "y = np.array([\n",
    "              1, 2, 3\n",
    "])\n",
    "\n",
    "# Проверим shape первого батча\n",
    "iterator = batch_generator(X, y, 2)\n",
    "X_batch, y_batch = next(iterator)\n",
    "assert X_batch.shape == (2, 3), y_batch.shape == (2,)\n",
    "assert np.allclose(X_batch, X[:2]), np.allclose(y_batch, y[:2])\n",
    "\n",
    "# Проверим shape последнего батча (их всего два)\n",
    "X_batch, y_batch = next(iterator)\n",
    "assert X_batch.shape == (1, 3), y_batch.shape == (1,)\n",
    "assert np.allclose(X_batch, X[2:]), np.allclose(y_batch, y[2:])\n",
    "\n",
    "# Проверим, что итерации закончились\n",
    "iter_ended = False\n",
    "try:\n",
    "    next(iterator)\n",
    "except StopIteration:\n",
    "    iter_ended = True\n",
    "assert iter_ended\n",
    "\n",
    "# Еще раз проверим то, сколько батчей создает итератор\n",
    "X = np.random.randint(0, 100, size=(1000, 100))\n",
    "y = np.random.randint(-1, 1, size=(1000, 1))\n",
    "num_iter = 0\n",
    "for _ in batch_generator(X, y, 3):\n",
    "    num_iter += 1\n",
    "assert num_iter == (1000 // 3 + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJ9_3VfrkQMv"
   },
   "source": [
    "# Задание 2. Обучите модель для классификации звезд\n",
    "\n",
    "Загрузите датасет из файла sky_data.csv, разделите его на train/test и обучите на нем нейронную сеть (архитектура ниже). Обучайте на батчах с помощью оптимизатора Adam, lr подберите сами, пробуйте что-то вроде 1e-2\n",
    "\n",
    "Архитектура:\n",
    "\n",
    "1. Dense Layer с relu активацией и 50 нейронами\n",
    "2. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте 50%) \n",
    "3. BatchNorm\n",
    "4. Dense Layer с relu активацией и 100 нейронами\n",
    "5. Dropout 80% (если другой keep rate дает сходимость лучше, то можно изменить) (попробуйте для разнообразия 50%)\n",
    "6. BatchNorm\n",
    "7. Выходной Dense слой c количеством нейронов, равному количеству классов\n",
    "\n",
    "Лосс - CrossEntropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qTd7VFMskQMw"
   },
   "source": [
    "В датасете классы представлены строками, поэтому классы нужно закодировать. Для этого в строчке ниже объявлен dict, с помощью него и функции map превратите столбец с таргетом в целое число. Кроме того, за вас мы выделили признаки, которые нужно использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTMs6bU6kQMx"
   },
   "source": [
    "### Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ci8mdz99kQMy"
   },
   "outputs": [],
   "source": [
    "feature_columns = ['ra', 'dec', 'u', 'g', 'r', 'i', 'z', 'run', 'camcol', 'field']\n",
    "target_column = 'class'\n",
    "\n",
    "target_mapping = {\n",
    "    'GALAXY': 0,\n",
    "    'STAR': 1,\n",
    "    'QSO': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2450,
     "status": "ok",
     "timestamp": 1586246030358,
     "user": {
      "displayName": "Yury Yarovikov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip8__BUAkkFW7zB1tjXwB7Y8uEezomM5ErVG2V=s64",
      "userId": "05223355485824927663"
     },
     "user_tz": -180
    },
    "id": "QRcIYVvUkQM2",
    "outputId": "8c6b62aa-45d3-4a89-bc39-6470c22861f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GALAXY    4998\n",
       "STAR      4152\n",
       "QSO        850\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('https://drive.google.com/uc?id=1K-8CtATw6Sv7k2dXco1fL5MAhTbKtIH3')\n",
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1446,
     "status": "ok",
     "timestamp": 1586246142286,
     "user": {
      "displayName": "Yury Yarovikov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gip8__BUAkkFW7zB1tjXwB7Y8uEezomM5ErVG2V=s64",
      "userId": "05223355485824927663"
     },
     "user_tz": -180
    },
    "id": "XQJyao1zoytL",
    "outputId": "bafda877-842b-42fe-9793-c765aee737a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objid</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>u</th>\n",
       "      <th>g</th>\n",
       "      <th>r</th>\n",
       "      <th>i</th>\n",
       "      <th>z</th>\n",
       "      <th>run</th>\n",
       "      <th>rerun</th>\n",
       "      <th>camcol</th>\n",
       "      <th>field</th>\n",
       "      <th>specobjid</th>\n",
       "      <th>class</th>\n",
       "      <th>redshift</th>\n",
       "      <th>plate</th>\n",
       "      <th>mjd</th>\n",
       "      <th>fiberid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.531326</td>\n",
       "      <td>0.089693</td>\n",
       "      <td>19.47406</td>\n",
       "      <td>17.04240</td>\n",
       "      <td>15.94699</td>\n",
       "      <td>15.50342</td>\n",
       "      <td>15.22531</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.722360e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.598371</td>\n",
       "      <td>0.135285</td>\n",
       "      <td>18.66280</td>\n",
       "      <td>17.21449</td>\n",
       "      <td>16.67637</td>\n",
       "      <td>16.48922</td>\n",
       "      <td>16.39150</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>267</td>\n",
       "      <td>3.638140e+17</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>323</td>\n",
       "      <td>51615</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.680207</td>\n",
       "      <td>0.126185</td>\n",
       "      <td>19.38298</td>\n",
       "      <td>18.19169</td>\n",
       "      <td>17.47428</td>\n",
       "      <td>17.08732</td>\n",
       "      <td>16.80125</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>268</td>\n",
       "      <td>3.232740e+17</td>\n",
       "      <td>GALAXY</td>\n",
       "      <td>0.123111</td>\n",
       "      <td>287</td>\n",
       "      <td>52023</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.870529</td>\n",
       "      <td>0.049911</td>\n",
       "      <td>17.76536</td>\n",
       "      <td>16.60272</td>\n",
       "      <td>16.16116</td>\n",
       "      <td>15.98233</td>\n",
       "      <td>15.90438</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.237650e+18</td>\n",
       "      <td>183.883288</td>\n",
       "      <td>0.102557</td>\n",
       "      <td>17.55025</td>\n",
       "      <td>16.26342</td>\n",
       "      <td>16.43869</td>\n",
       "      <td>16.55492</td>\n",
       "      <td>16.61326</td>\n",
       "      <td>752</td>\n",
       "      <td>301</td>\n",
       "      <td>4</td>\n",
       "      <td>269</td>\n",
       "      <td>3.722370e+18</td>\n",
       "      <td>STAR</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>3306</td>\n",
       "      <td>54922</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          objid          ra       dec         u         g         r         i  \\\n",
       "0  1.237650e+18  183.531326  0.089693  19.47406  17.04240  15.94699  15.50342   \n",
       "1  1.237650e+18  183.598371  0.135285  18.66280  17.21449  16.67637  16.48922   \n",
       "2  1.237650e+18  183.680207  0.126185  19.38298  18.19169  17.47428  17.08732   \n",
       "3  1.237650e+18  183.870529  0.049911  17.76536  16.60272  16.16116  15.98233   \n",
       "4  1.237650e+18  183.883288  0.102557  17.55025  16.26342  16.43869  16.55492   \n",
       "\n",
       "          z  run  rerun  camcol  field     specobjid   class  redshift  plate  \\\n",
       "0  15.22531  752    301       4    267  3.722360e+18    STAR -0.000009   3306   \n",
       "1  16.39150  752    301       4    267  3.638140e+17    STAR -0.000055    323   \n",
       "2  16.80125  752    301       4    268  3.232740e+17  GALAXY  0.123111    287   \n",
       "3  15.90438  752    301       4    269  3.722370e+18    STAR -0.000111   3306   \n",
       "4  16.61326  752    301       4    269  3.722370e+18    STAR  0.000590   3306   \n",
       "\n",
       "     mjd  fiberid  \n",
       "0  54922      491  \n",
       "1  51615      541  \n",
       "2  52023      513  \n",
       "3  54922      510  \n",
       "4  54922      512  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40-ivv77p9I2"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# Extract Features\n",
    "le = preprocessing.LabelEncoder()\n",
    "data['class'] = le.fit_transform(data['class'])\n",
    "X = data.drop(['class','objid','specobjid','redshift','plate','mjd','fiberid'], 1)\n",
    "# Extract target\n",
    "y = data['class']\n",
    "# encode target with target_mapping\n",
    "y = pd.DataFrame(map(target_mapping.get,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A3OkZT7HkQM7"
   },
   "source": [
    "Нормализация фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynmXS7dMkQM8"
   },
   "outputs": [],
   "source": [
    "# Просто вычтите среднее и поделитe на стандартное отклонение (с помощью пандас). Также преобразуйте всё в np.array\n",
    "X = np.array((X - X.mean(axis=0))/X.std(axis=0))\n",
    "#y = np.array(y)\n",
    "y = np.array(y).squeeze(1)\n",
    "#print (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEIewITCqo38"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-3bbab44da409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Проверьте, что получившиеся массивы являются np.ndarray'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Данные не отнормированы'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert type(X) == np.ndarray and type(y) == np.ndarray, 'Проверьте, что получившиеся массивы являются np.ndarray'\n",
    "assert np.allclose(y[:5], [1,1,0,1,1])\n",
    "assert X.shape == (10000, 10)\n",
    "assert np.allclose(X.mean(axis=0), np.zeros(10)) and np.allclose(X.std(axis=0), np.ones(10)), 'Данные не отнормированы'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VTcR3q0SkQNj"
   },
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5AFbCY4kQNk"
   },
   "outputs": [],
   "source": [
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# Превратим данные в тензоры, чтобы потом было удобнее\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDCt0vtlkQNo"
   },
   "source": [
    "Хорошо, данные мы подготовили, теперь надо объявить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fI6ZqCaCkQNp"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42) \n",
    "np.random.seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X.shape[],50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.8),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.Linear(50,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.8),\n",
    "    nn.BatchNorm1d(100),\n",
    ")\n",
    "    \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=1e-2, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GkUkeHfokQNs"
   },
   "source": [
    "### Обучающий цикл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41jYcT6AkQNt"
   },
   "outputs": [],
   "source": [
    "def train(X_train, y_train, X_test, y_test, num_epoch):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(num_epoch):\n",
    "        epoch_train_losses = []\n",
    "        for X_batch, y_batch in batch_generator(X_train, y_train, 500):\n",
    "            # На лекции мы рассказывали, что дропаут работает по-разному во время обучения и реального предсказания\n",
    "            # Чтобы это учесть нам нужно включать и выключать режим обучения, делается это командой ниже\n",
    "            model.train(True)\n",
    "            # Посчитаем предсказание и лосс\n",
    "            y_pred = model(X_batch)\n",
    "            loss_train = loss_fn(y_pred,y_batch)\n",
    "            # зануляем градиент\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # backward\n",
    "            loss.backward()\n",
    "            \n",
    "            # ОБНОВЛЯЕМ веса\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Запишем число (не тензор) в наши батчевые лоссы\n",
    "            epoch_train_losses.append(loss_train)        \n",
    "        train_losses.append(np.mean(epoch_train_losses))\n",
    "        \n",
    "        # Теперь посчитаем лосс на тесте\n",
    "        model.train(False)\n",
    "        with torch.no_grad():\n",
    "            # Сюда опять же надо положить именно число равное лоссу на всем тест датасете\n",
    "            y_pred_test = model(X_test)\n",
    "            loss_test = loss_fn(y_pred_test,y_test)\n",
    "            test_losses.append(loss_test)\n",
    "            \n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idGcIKlIth3D"
   },
   "outputs": [],
   "source": [
    "def check_loss_decreased():\n",
    "    print(\"На графике сверху, точно есть сходимость? Точно-точно? [Да/Нет]\")\n",
    "    s = input()\n",
    "    if s.lower() == 'да':\n",
    "        print(\"Хорошо!\")\n",
    "    else:\n",
    "        raise RuntimeError(\"Можно уменьшить дропаут, уменьшить lr, поправить архитектуру, etc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cDyg5zMckQOX",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Подберите количество эпох так, чтобы график loss сходился\n",
    "train_losses, test_losses = train(X_train, y_train, X_test, y_test, num_epoch=600) # не уверена что график \n",
    "                            #будет сходится, так как времени для подбора было не достаточно\n",
    "\n",
    "print('train loss: {:.4f}\\ntest loss: {:.4f}'.format(train_losses[-1], \n",
    "                                                     test_losses[-1].item()))\n",
    "plt.plot(range(len(train_losses)), train_losses, label='train')\n",
    "plt.plot(range(len(test_losses)), test_losses, label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "    \n",
    "check_loss_decreased()\n",
    "assert train_losses[-1] < 0.3 and test_losses[-1] < 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UV1jaOM1SuTL"
   },
   "source": [
    "### Вычислите accuracy получившейся модели на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXqXflGcTBKS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "train_pred_labels = model.forward(X_train)#YOUR CODE: use forward\n",
    "test_pred_labels = model.forward(X_test)#YOUR CODE: use forward\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred)# YOUR CODE)\n",
    "test_acc = accuracy_score(y_test, y_pred)# YOUR CODE)\n",
    "\n",
    "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
    "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n",
    "\n",
    "print(\"Train accuracy: {}\\nTest accuracy: {}\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IB1XswA2kQOd"
   },
   "source": [
    "# Задание 3. Исправление ошибок в архитектуре\n",
    "\n",
    "Только что вы обучили полносвязную нейронную сеть. Теперь вам предстоит проанализировать архитектуру нейронной сети ниже, исправить в ней ошибки и  обучить её с помощью той же функции train. Пример исправления ошибок есть в семинаре Григория Лелейтнера.\n",
    "\n",
    "Будьте осторожнее и убедитесь, что перед запуском train вы вновь переопределили все необходимые внешние переменные (train обращается к глобальным переменным, в целом так делать не стоит, но сейчас это было оправдано, так как иначе нам пришлось бы передавать порядка 7-8 аргументов).\n",
    "\n",
    "Чтобы у вас получилась такая же архитектура, как у нас, и ответы совпали, давайте определим некоторые правила, как исправлять ошибки:\n",
    "\n",
    "1. Если вы видите лишний нелинейный слой, который стоит не на своем месте, просто удалите его. (не нужно добавлять новые слои, чтобы сделать постановку изначального слоя разумной. Удалять надо самый последний слой, который все портит. Для линейных слоев надо что-то исправить, а не удалить его)\n",
    "2. Если у слоя нет активации, то добавьте ReLU или другую подходящую активацию\n",
    "3. Если что-то не так с learning_rate, то поставьте 1e-2\n",
    "4. Если что-то не так с параметрами, считайте первый параметр, который появляется, как верный (т.е. далее в сети должен использоваться он).\n",
    "5. Ошибки могут быть и в полносвязных слоях. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Un7PyM39kQOe"
   },
   "source": [
    "Задача все та же - классификация небесных объектов на том же датасете. После исправления сети вам нужно обучить ее.\n",
    "\n",
    "**Ответ на задачу - средний лосс на тестовом датасете**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3M9P67WekQOe"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "# WRONG ARCH\n",
    "model = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(6, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(100, 200),\n",
    "    nn.Softmax(),\n",
    "    nn.Linear(200, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(200, 3),\n",
    "    nn.Dropout(p=0.5)\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters[:-2], lr=1e-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0HEx6vbkQOi"
   },
   "outputs": [],
   "source": [
    "# RIGHT ARCH\n",
    "torch.manual_seed(42)   \n",
    "np.random.seed(42)\n",
    "model = nn.Sequential(\n",
    "    <YOUR CODE>\n",
    ")\n",
    "\n",
    "\n",
    "loss_fn = <YOUR CODE>\n",
    "optimizer = <YOUR CODE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oGhmQg06gGiT"
   },
   "source": [
    "### Обучите и протестируйте модель так же, как вы это сделали в задаче 2. Вычислите accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7SZv9yARkQOo"
   },
   "outputs": [],
   "source": [
    "#YOUR CODE\n",
    "\n",
    "train_acc = <YOUR CODE>\n",
    "test_acc = <YOUR CODE>\n",
    "\n",
    "\n",
    "assert train_acc > 0.9, \"Если уж классифицировать звезды, которые уже видел, то не хуже, чем в 90% случаев\"\n",
    "assert test_acc > 0.9, \"Новые звезды тоже надо классифицировать хотя бы в 90% случаев\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4. Опишите в чем заключались ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "In4h-bM_g0Vb"
   },
   "source": [
    "## Задание 5. Опишите модель лематизации \n",
    "Необходимо описать пошагово на примере реализацию с помощью архитектуры Transformer состоящей из Encoder и Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Лемматизация - это процесс, который используется для приведения слова в неопределенную форму. Основное отличие от других\n",
    "видов, это то что лемматизация учитывает значение слова, а не удаляет последние символы. \n",
    "В архитектуре Transformer encoder получает на вход слова и выдает векторное значение. И каждое слово проводит через \n",
    "слои такие как fully-connected layers или shortcut connections. Но в архитектуре Transformer есть еще новый слой под названием Multi-head attention.\n",
    "Этот слой преобразовывает входящие вектора и вычитывает их скалярное произведение. потом результат всех этих параллельных attentionов еще раз прогоняется \n",
    "через обучаемое линейное преобразование и выдает один вектор того же размера, что и каждый из входов. Этот метод используется не только для того чтобы понимать\n",
    "значение слова, но также выявить аспекты этого слова. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]neural_networks_pytorch.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
